{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28923d3e-db19-4b5a-9a20-23bbfeb06e3c",
   "metadata": {},
   "source": [
    "# **STEP 1: Data Importing and Pre-processing**\n",
    "## - Import dataset and describe characteristics such as dimensions, data types, file types, and import methods used\n",
    "## - Clean, wrangle, and handle missing data\n",
    "## - Transform data appropriately using techniques such as aggregation, normalization, and feature construction\n",
    "## - Reduce redundant data and perform need-based discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cc050446-5481-4592-bd14-1b658a6f8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages used for the project in the first cell, use code cells for code and comments, \n",
    "#and use markdown cells for headings and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "27f5d4ef-9bd0-4726-aec6-dd5348d2e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "8fe3572f-90ad-4f37-93f4-1a04ffdc153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "2  5631500400  20150225T000000  180000.0       2.0       1.00        770.0   \n",
       "3  2487200875  20141209T000000  604000.0       4.0       3.00       1960.0   \n",
       "4  1954400510  20150218T000000  510000.0       3.0       2.00       1680.0   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0    5650.0     1.0           0     0  ...      7        1180              0   \n",
       "1    7242.0     2.0           0     0  ...      7        2170            400   \n",
       "2   10000.0     1.0           0     0  ...      6         770              0   \n",
       "3    5000.0     1.0           0     0  ...      7        1050            910   \n",
       "4    8080.0     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/Users/vrb/Downloads/')\n",
    "\n",
    "df = pd.read_csv(\"house_sales.csv\", header = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efea050-2672-4c52-b7c6-39e781402186",
   "metadata": {},
   "source": [
    "Basic Characteristics\n",
    "\n",
    "1. Shape of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c9228-7cc5-4bf2-ab3e-61a9b2f682f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape (rows, columns):\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d8181-7412-42e4-9ff1-68fa62b30320",
   "metadata": {},
   "source": [
    "2. Defining file type:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c6af4-5d64-44fe-ad61-7b8c635d474b",
   "metadata": {},
   "source": [
    "The dataset was provided as a CSV file, which is a plain-text tabular file commonly used for structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3781421-5caa-4d0b-bc96-1707a989400c",
   "metadata": {},
   "source": [
    "2. Data types by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4492a77-83bf-49dd-b510-56d4353269c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ba6eb-8682-4524-8f8c-00edbae131df",
   "metadata": {},
   "source": [
    "3. Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44301241-b948-4ad7-b338-6466bf892756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6682f-0335-483f-b0d2-1fcb739e474c",
   "metadata": {},
   "source": [
    "Cleaning the data\n",
    "\n",
    "1. Separating missing value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c1a2d-7687-4aea-8a5e-a8c610b3307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_na = [\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\"]\n",
    "\n",
    "df_na = df[cols_na]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c69ce-73ad-46a1-abae-c8d4fc683df2",
   "metadata": {},
   "source": [
    "2. Missing percentage in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa2ce4-ed2a-4b82-9a6f-8935a5e09482",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = (df_na.isna().sum() / len (df_na)) * 100\n",
    "print (\"Missing percent: \\n\", missing_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c286f9-8a78-40d4-87a4-b09bb9a2dbb6",
   "metadata": {},
   "source": [
    "4. Distribution in missing value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb753f-11ae-404b-a232-9249790ab79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bedrooms\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e2170-18ad-4aca-a2c2-cfa5a9a14e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b54b57-c13a-4a52-84eb-08f8eb3f650e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7c289bb-5822-4ce7-9a77-bed8efa80bee",
   "metadata": {},
   "source": [
    "5. Filling in missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82d7a8-a070-47df-aace-9aead1fed04c",
   "metadata": {},
   "source": [
    "    a. bedrooms\n",
    "        This columns missing percentage is under 10% and the variable is discrete with clear central tendency. Most homes have 3 bedrooms, due to outliers, the mean would not be a reliable choice. The median is more robust to those outliers and better represents a typical value. For these reasons, the median, was used to fill the missing bedroom values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16ab55-5e9a-48ca-b241-cee1ce56ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bedrooms\"] = df[\"bedrooms\"].fillna(df[\"bedrooms\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d40538-ac35-491b-912c-bb7579b6207e",
   "metadata": {},
   "source": [
    "    b. bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855205c-0d91-4374-a75c-735d820eb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms\"] = df [\"bathrooms\"].fillna(df[\"bathrooms\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb93f6-9fbe-4075-994e-652c2a8898be",
   "metadata": {},
   "source": [
    "    c. sqft_living \n",
    "    Missing values in this columns were filled using the median for each bedroom count to keep estimates accruate. sqft_living15 was avoided becasue it represents nearby homes, not the specific property.\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034b3be-fda4-4710-a80f-c4a830ad734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in sorted(df['bedrooms'].unique()):\n",
    "    \n",
    "    mis_sq = (df['bedrooms'] == b) & (df['sqft_living'].isna())\n",
    "\n",
    "    median_sqft = df.loc[df['bedrooms'] == b, 'sqft_living'].median()\n",
    "\n",
    "    df.loc[mis_sq, 'sqft_living'] = median_sqft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4215f-455f-4ed1-a61a-ef4522e17d7c",
   "metadata": {},
   "source": [
    "    d. sqft_lot\n",
    "        Misisng values in sqft_lot were filled by using median lot size within each zip code. Lot size varies heavily by location, so grouping by zip code provides more realistic estimates than using one overall median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7bdabf-9815-4b1a-a5c2-25e044efca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in sorted(df['zipcode'].unique()):\n",
    "    \n",
    "    zip = (df['zipcode'] == z) & (df['sqft_lot'].isna())\n",
    "    \n",
    "    median_lot = df.loc[df['zipcode'] == z, 'sqft_lot'].median()\n",
    "    \n",
    "    df.loc[zip, 'sqft_lot'] = median_lot\n",
    "\n",
    "                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5c585-e520-4f0e-a377-4215392143c4",
   "metadata": {},
   "source": [
    " 6. Converting data types\n",
    "\n",
    "    a. date\n",
    "        The date column was converted to datetime to allow accurate time-based calculations and avoid treating the values as plain text, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82192d-56ac-4d17-8e8d-77bf7ad2d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['date'].head()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc67dd-622a-484d-9618-6ce691524663",
   "metadata": {},
   "source": [
    "7. Duplicate checks and redundant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d7002-d50b-4eeb-8131-05b29a665903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545102bd-c6d6-4369-b4d4-cc2c526b0ece",
   "metadata": {},
   "source": [
    "8. Impossible data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee405b7-3cdb-4149-8930-5e1d235d50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['bedrooms'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07955f5-fad2-44f4-8ddd-dfaa45dde9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['bathrooms'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed70339-acec-44b4-9237-dd0722e849d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['floors'] < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9baae-6ac7-4140-8bb6-050e62819926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sqft_living'] <= 0]\n",
    "df[df['sqft_lot'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb0274-7f82-4f6f-ad14-7afc57cf6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['price'] <= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb1e45f-e6e7-4e4e-a6bb-24ea480403e9",
   "metadata": {},
   "source": [
    "9. Outliers\n",
    "    \n",
    "    a. bedrooms\n",
    "       A single extreme outlier was found in the bedrooms column where a property was listed with 33 bedroomsl. Based on the sq footage of the home, bathrooms and price, this was ultimatley determined to be a data entry error, and the value was corrected to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8e413-9604-40d8-9e71-1d07094770a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'bedrooms'\n",
    "\n",
    "Q1 = df[col].quantile(0.25)\n",
    "Q3 = df[col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "df[(df[col] < lower) | (df[col] > upper)][['bedrooms']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543974e6-1219-4412-b233-76b93078362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df ['bedrooms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba47e0-957d-4141-abc2-5f3d29252b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['bedrooms'] > 10][['bedrooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91164c-9c9d-4dc9-ac22-91f0ecbb4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[15870]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b650c-42f1-41aa-b16c-aeea9b26bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[15870, 'bedrooms'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b7eb7-e77a-46ec-b52c-1ea6541a59d8",
   "metadata": {},
   "source": [
    "    b. bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4434d0d-bcf8-40d2-b81a-d356842ad653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bathrooms'].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43952ff7-8739-4a6d-9682-552d7cd8eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bathrooms'].sort_values().head(10)\n",
    "df['bathrooms'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95de0a-9cb5-4d95-9fe2-01121745d69b",
   "metadata": {},
   "source": [
    "    c. sqft_living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa2c63-a607-424d-8038-cbc650d6794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_living'].describe()\n",
    "df['sqft_living'].sort_values().head(20)\n",
    "df['sqft_living'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3928ad-1c63-416a-8323-b3ab786c0147",
   "metadata": {},
   "source": [
    "    d. sqft_lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d75ee7-f929-4eec-8506-1508b737ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_lot'].describe()\n",
    "df['sqft_lot'].sort_values().head(10)\n",
    "df['sqft_lot'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0dd7b6-5371-4973-bc33-6a709b6df7ab",
   "metadata": {},
   "source": [
    "    e. floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc443f-462c-441a-a0e4-816233cf7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['floors'].describe()\n",
    "df['floors'].sort_values().head(10)\n",
    "df['floors'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb623d-8ac0-4fa9-98a3-cda2ba918f3f",
   "metadata": {},
   "source": [
    "    f. condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e6fa8-b2f6-44c6-91f3-b0fd3cb319cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'].describe()\n",
    "df['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac31eec-5ba4-4211-867a-4d30c41f80b3",
   "metadata": {},
   "source": [
    "    g. grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b511c7f-75a0-447b-a09f-596c13879913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grade'].describe()\n",
    "df['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03c52a-77ab-4bb6-a7c0-85a4e9cc2013",
   "metadata": {},
   "source": [
    "    h. yr_built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9597b-6b47-433f-a9af-22192c0c1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_built'].sort_values().head(10)\n",
    "df['yr_built'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f7b66-a7ee-46af-af2c-beb58c6f3156",
   "metadata": {},
   "source": [
    "    i. sqft_living15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af573c07-ed26-4fc6-8935-a0d5ea0feeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_living15'].describe()\n",
    "df['sqft_living15'].sort_values().head(10)\n",
    "df['sqft_living15'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a18cf9-8601-4896-93f8-2aac53b6aa9b",
   "metadata": {},
   "source": [
    "    j. sqft_lot15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa6cc6-7c17-4cbb-abc3-c9ca6a4fcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_lot15'].describe()\n",
    "df['sqft_lot15'].sort_values().head(10)\n",
    "df['sqft_lot15'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8ae29-6fc7-450c-93b9-4b81e8da8c38",
   "metadata": {},
   "source": [
    "    k. price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222a4dd-5a32-4ece-93c3-edf4d4ad53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('price', ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c1852-0646-4ada-b82d-578bfd968b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('price', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3b069-1b2e-4ea6-88e5-cc18851000ee",
   "metadata": {},
   "source": [
    "10. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41bb56-94b7-406f-84ac-f6c0adea7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0780b95-1e8a-4aaa-bfc3-2e65bec79b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c75f8-52bf-449c-a06c-a07341dd0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f22d5-1ef4-4335-a743-5d0bb02ac984",
   "metadata": {},
   "source": [
    "# **STEP 2: Data Analysis and Visualization**\n",
    "## -Identify categorical, ordinal, and numerical variables within the data\n",
    "## -Provide measures of centrality and distribution with visualizations\n",
    "## -Diagnose for correlations between variables and determine independent and dependent variables\n",
    "## -Perform exploratory analysis in combination with visualization techniques to discover patterns and features of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd130c-2749-4347-a274-b7377090ec1e",
   "metadata": {},
   "source": [
    "**2.1 Identify categorical, ordinal, and numerical values within the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801149d9-84d0-4e1a-8cd5-2caac65adc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_columns = df.shape[1]\n",
    "print(total_num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c869929-2d1c-4449-9be6-5b18b4f8be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible data types in pandas include numbers (integer and float), objects, strings, datetimes, timedeltas, categories, and datetimez.\n",
    "\n",
    "numerical_col = df.select_dtypes(include = 'number').columns\n",
    "numerical_col_count = len(numerical_col)\n",
    "print(\"Numerical data =\", list(numerical_col))\n",
    "print(\"Number of numerical columns =\", numerical_col_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7dad55-d4f6-4e91-8d23-d3769dcf6ef0",
   "metadata": {},
   "source": [
    "Pandas. Dataframe. Select_dtypes—Pandas 2. 3. 3 documentation. (n.d.). Retrieved November 24, 2025, from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d7f46-82e0-4ede-bfbb-acf3ca0f7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of the 21 columns, 20 are numerical. Therefore, there is one remaining non-numerical column.\n",
    "# The process for numerical data will be repeated for object, datetime, and categorical data.\n",
    "\n",
    "# object data\n",
    "object_col = df.select_dtypes(include = 'object').columns\n",
    "object_col_count = len(object_col)\n",
    "print(\"Object data =\", list(object_col))\n",
    "print(\"Number of object columns =\", object_col_count)\n",
    "\n",
    "# datetimes\n",
    "datetime_col = df.select_dtypes(include = 'datetime64').columns\n",
    "datetime_col_count = len(datetime_col)\n",
    "print(\"Datetime data =\", list(datetime_col))\n",
    "print(\"Number of datetime columns =\", datetime_col_count)\n",
    "\n",
    "# categories\n",
    "categorical_col = df.select_dtypes(include = 'category').columns\n",
    "categorical_col_count = len(categorical_col)\n",
    "print(\"Categorical data =\", list(categorical_col))\n",
    "print(\"Number of categorical columns =\", categorical_col_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4437991-3e04-4cd8-a04c-09c3142547ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = df.dtypes\n",
    "data_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60790f9-f4e0-42b1-9bbe-af5241585d60",
   "metadata": {},
   "source": [
    "Of the 21 total columns in the house sales data frame, **20 contain numerical data and 1 contains ordinal, specifically datetime, data**.\n",
    "The output from the earlier script was verified with df.dtypes. The listed data types align with the df.info() output from Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd3e52-8d18-4034-af9c-6e29ca997632",
   "metadata": {},
   "source": [
    "**2.2 Provide measures of centrality and distributions with visualizations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ded9ed-49a7-489e-be70-8fcee98e6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "# Dates are not technically a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median date =\", df['date'].median())\n",
    "print(\"mode date = \", df['date'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa3fe0-62ae-4843-b19a-75f0f099c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the square root of the number of entries to determine the number of boxes.\n",
    "\n",
    "import math\n",
    "\n",
    "print(round(math.sqrt(21613), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3599c40-78a9-416d-9ad1-2df32f969b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Increase figure width\n",
    "ax.hist(df['date'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "ax.set_title ('Histogram of Date')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08536f79-b9ef-413f-a2e3-0033e676b1bf",
   "metadata": {},
   "source": [
    "I used ChatGPT to help me reformat the histogram. Originally, the figure was too small to draw any conclusions. Therefore, I entered my original code (plt.hist()), and ChatGPT helped me to set the values as dates, replot the data using Axes, rather than pyplot, expand the x-axis, and increase the number of intervals to visualize the fluctuations over time.\n",
    "\n",
    "Chatgpt. (n.d.). ChatGPT. Retrieved November 24, 2025, from https://chatgpt.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561d615-f71f-4eb4-bf74-001fdc1a29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price\n",
    "\n",
    "print(\"mean price = $\", df['price'].mean().round(2))\n",
    "print(\"median price = $\", df['price'].median())\n",
    "print(\"mode price = $\", df['price'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1dedba-dbc8-4fcd-9427-7bee3428269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous result suggests that there are two modes: $350,000.00 and $450,000.00, so I want to count the number of rows with those prices.\n",
    "\n",
    "df.loc[df['price'] == 350000,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ed9cc-829b-4db8-9ac9-5a7637a1b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['price'] == 450000,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2e315-65c4-437f-a160-926178bc93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['price'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Price')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['price'])\n",
    "plt.title ('Boxplot of Price')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e57b0-caa3-4154-941a-97cfc99c980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bedrooms\n",
    "# The number of bedrooms is not a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median bedrooms =\", df['bedrooms'].median())\n",
    "print(\"mode bedrooms =\", df['bedrooms'].mode())\n",
    "print(\"max number of bedrooms =\", df['bedrooms'].max())\n",
    "print(\"min number of bedrooms =\", df['bedrooms'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3792058-ae7b-4eca-bc92-209fd830a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "# The range of number of bedrooms is 0 to 10, therefore 10 bins are used in the histogram.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['bedrooms'], bins=11, range = (0, 11), color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Number of Bedrooms')\n",
    "plt.xlabel('Bedrooms')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d585f2f-7356-4dbc-be90-fd442ba2ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bathrooms\n",
    "# The number of bathrooms is not a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median bathrooms =\", df['bathrooms'].median())\n",
    "print(\"mode bathrooms =\", df['bathrooms'].mode())\n",
    "print(\"max number of bathrooms =\", df['bathrooms'].max())\n",
    "print(\"min number of bathrooms =\", df['bathrooms'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075eb851-9c0a-4c11-87e4-ee5196abbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "# The range of number of bathrooms is 0 to 8, therefore 8 bins are used in the histogram.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['bathrooms'], bins=9, range = (0, 9), color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Number of Bathrooms')\n",
    "plt.xlabel('Bathrooms')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3c47b-8f7c-4547-a6d3-f13e412dbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living\n",
    "\n",
    "print(\"mean living sqft =\", df['sqft_living'].mean().round(2), \"ft\\u00b2\")\n",
    "print(\"median living sqft =\", df['sqft_living'].median(), \"ft\\u00b2\")\n",
    "print(\"mode living sqft =\", df['sqft_living'].mode(), \"ft\\u00b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc2b9e-9dde-47da-b0d2-272c76c0fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['sqft_living'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Living Space Size')\n",
    "plt.xlabel('Area (sqft)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['sqft_living'])\n",
    "plt.title ('Boxplot of Living Space Size')\n",
    "plt.ylabel('Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a525a9-9d14-4b3e-a18a-d6f782051346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_lot\n",
    "\n",
    "print(\"mean lot sqft =\", df['sqft_lot'].mean().round(2), \"ft\\u00b2\")\n",
    "print(\"median lot sqft =\", df['sqft_lot'].median(), \"ft\\u00b2\")\n",
    "print(\"mode lot sqft =\", df['sqft_lot'].mode(), \"ft\\u00b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d56df7-8b32-4178-b1d9-a4d625362772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['sqft_lot'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Lot Size')\n",
    "plt.xlabel('Area (ft\\u00b2)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['sqft_living'])\n",
    "plt.title ('Boxplot of Lot Size')\n",
    "plt.ylabel('Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5f0ff-3ad5-44e0-bead-234715accd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# floors\n",
    "# The number of floors is not a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median floors =\", df['floors'].median())\n",
    "print(\"mode floors =\", df['floors'].mode())\n",
    "print(\"max number of floors =\", df['floors'].max())\n",
    "print(\"min number of floors =\", df['floors'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840b797-9bf9-4ac2-a251-c619984a39ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "# The range of number of bathrooms is 1 to 3.5, therefore 6 bins are used in the histogram.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['floors'], bins = 6, range = (1, 4), color = 'steelblue', edgecolor = 'none')\n",
    "plt.title ('Histogram of Number of Floors')\n",
    "plt.xlabel('Floors')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76ba8b-eddc-4cfc-8b9e-b89a3d4c4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waterfront\n",
    "# The presence (=1) or absence (=0) of a waterfront view is binary, therefore, it does not make sense to calculate the median.\n",
    "# Although the dataset is a binary, the mean can illuminate a intermediate measure of centrality between 0 and 1.\n",
    "\n",
    "print(\"mean waterfront =\", df['waterfront'].mean())\n",
    "print(\"mode waterfront =\", df['waterfront'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374ed8f-85e4-41cd-9574-0792e47c66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the frequency of a waterfront view.\n",
    "# The presence or absence of a waterfront view is a binary dataset. Therefore only 2 bins are needed.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['waterfront'], bins = 2, color = 'steelblue', edgecolor = 'none')\n",
    "plt.title ('Frequency of a Waterfront View')\n",
    "plt.xlabel('Waterfront View')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e805a-708d-4ce9-b6a3-225a59f54033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view\n",
    "# The presence (=1) or absence (=0) of a view is binary, therefore, it does not make sense to calculate the median.\n",
    "# Although the dataset is a binary, the mean can illuminate a intermediate measure of centrality between 0 and 1.\n",
    "\n",
    "print(\"mean view =\", df['view'].mean())\n",
    "print(\"median view =\", df['view'].median())\n",
    "print(\"mode view =\", df['view'].mode())\n",
    "print(\"max score of view =\", df['view'].max())\n",
    "print(\"min score of view =\", df['view'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63482f73-4309-4df3-9903-cd33672ce9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the frequency of a view.\n",
    "# The presence or absence of a view is a binary dataset. Therefore only 2 bins are needed.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['view'], bins = 5, range = (0, 5), color = 'steelblue', edgecolor = 'none')\n",
    "plt.title ('Frequency of a View')\n",
    "plt.xlabel('View')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a1882-3151-47f6-b0b9-c677c706a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition\n",
    "# The score of the condition is not a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median condition =\", df['condition'].median())\n",
    "print(\"mode condition =\", df['condition'].mode())\n",
    "print(\"max score of condition =\", df['condition'].max())\n",
    "print(\"min score of condition =\", df['condition'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3a9dd-ed06-4d7b-a5db-01f60a5a67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "# The range of condition scores is 1 to 5, therefore 4 bins are used in the histogram.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['condition'], bins = 5, range = (1, 6), color = 'steelblue', edgecolor = 'none')\n",
    "plt.title ('Histogram of Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419c548-715b-4a5b-8129-39f28c249d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade\n",
    "# The grade is not a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median grade =\", df['grade'].median())\n",
    "print(\"mode grade =\", df['grade'].mode())\n",
    "print(\"max score of grade =\", df['grade'].max())\n",
    "print(\"min score of grade =\", df['grade'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ef290-2110-4b8f-89a5-130675a4ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "# The range of grades is 1 to 13, therefore 12 bins are used in the histogram.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['grade'], bins = 13, range = (1, 14), color = 'steelblue', edgecolor = 'none')\n",
    "plt.title ('Histogram of Grade of House')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59def6-808d-4970-84ec-f79fc7e2822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_above\n",
    "\n",
    "print(\"mean sqft above =\", df['sqft_above'].mean().round(1), \"ft\\u00b2\")\n",
    "print(\"median sqft above =\", df['sqft_above'].median(), \"ft\\u00b2\")\n",
    "print(\"mode sqft above =\", df['sqft_above'].mode(), \"ft\\u00b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eac0c0-54c1-4696-9aa3-4bbafaefb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['sqft_above'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Area Above')\n",
    "plt.xlabel('Area (ft\\u00b2)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['sqft_above'])\n",
    "plt.title ('Boxplot of Area Above')\n",
    "plt.ylabel('Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db062d-f25e-49bc-ae0c-71352207e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_basement\n",
    "\n",
    "print(\"mean basement sqft =\", df['sqft_basement'].mean().round(1))\n",
    "print(\"median basement sqft =\", df['sqft_basement'].median())\n",
    "print(\"mode basement sqft =\", df['sqft_basement'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa21e91-a3a2-40a0-adf8-bd14033e77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['sqft_basement'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Basement Size')\n",
    "plt.xlabel('Area (ft\\u00b2)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['sqft_basement'])\n",
    "plt.title ('Boxplot of Basement Size')\n",
    "plt.ylabel('Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7b63a-4229-4cf4-8490-c615c0dd306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year built\n",
    "# Dates are not technically a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median year built =\", df['yr_built'].median())\n",
    "print(\"mode year built = \", df['yr_built'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc2570-273c-4618-b559-6b33bc145980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['yr_built'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Year Built')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b3b64-32a1-4567-ba4d-9b0b9149083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year renovated\n",
    "# Dates are not technically a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"median year renovated =\", df['yr_renovated'].median())\n",
    "print(\"mode year renovated = \", df['yr_renovated'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d68d1b-35a8-486d-a53a-6fb051330e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of years that the houses were renovated.\n",
    "\n",
    "reno_yr = np.sort(df['yr_renovated'].unique())\n",
    "print(reno_yr)\n",
    "\n",
    "reno_yr_count = df['yr_renovated'].value_counts().sort_index()\n",
    "print(reno_yr_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215177c-529e-4c23-836d-e75a2bceebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a bar chart to look at the frequency of houses renovated.\n",
    "\n",
    "reno_yr_string = reno_yr.astype(str)\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.bar(reno_yr_string, reno_yr_count.values)\n",
    "plt.xlabel(\"Year Renovated\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Bar Chart of Renovation Year\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993060e-5589-4099-b9f1-1b03743eac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipcode\n",
    "# Zipcodes are not a continuous dataset, therefore, it does not make sense to calculate the mean.\n",
    "\n",
    "print(\"zipcode median =\", df['zipcode'].median())\n",
    "print(\"zipcode mode = \", df['zipcode'].mode())\n",
    "print(\"zipcode range =\", df['zipcode'].max() - df['zipcode'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fd973-399a-4161-b4eb-e88b23b4ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram to look at the spread of the data.\n",
    "# The zipcode range is 198, therefore 198 bins are used in the histogram.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['zipcode'], bins=198, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Zipcode')\n",
    "plt.xlabel('Zipcode')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6aab0-7201-4d9d-bedb-759ea86fbe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat\n",
    "\n",
    "print(\"mean latitude =\", df['lat'].mean().round(1))\n",
    "print(\"median latitude =\", df['lat'].median())\n",
    "print(\"mode latitude =\", df['lat'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1b0ec-6396-4748-9657-8d97eef1356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous result suggests that there are four modes: 47.5322, 47.5491, 47.6624, and 47.6846, so I want to count the number of rows with those prices.\n",
    "\n",
    "lat_mode_1 = df['lat'] == 47.5322\n",
    "print(\"lat_mode_1 =\", lat_mode_1.sum())\n",
    "\n",
    "lat_mode_2 = df['lat'] == 47.5491\n",
    "print(\"lat_mode_2 =\", lat_mode_2.sum())\n",
    "\n",
    "lat_mode_3 = df['lat'] == 47.6624\n",
    "print(\"lat_mode_3 =\", lat_mode_3.sum())\n",
    "\n",
    "lat_mode_4 = df['lat'] == 47.6846\n",
    "print(\"lat_mode_4 =\", lat_mode_4.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29974a-bd48-4512-909a-4e01144a6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['lat'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Latitude')\n",
    "plt.xlabel('Latitude (coordinate)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['lat'])\n",
    "plt.title ('Boxplot of Latitude')\n",
    "plt.ylabel('Latitude (coordinate)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f1db9-c118-4735-b4ac-74c02f16e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat\n",
    "\n",
    "print(\"mean longitude =\", df['long'].mean().round(1))\n",
    "print(\"median longitude =\", df['long'].median())\n",
    "print(\"mode longitude =\", df['long'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008df221-1a55-44c2-9aa4-8258c8fd91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['long'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Longitude')\n",
    "plt.xlabel('Longitude (coordinate)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['long'])\n",
    "plt.title ('Boxplot of Longitude')\n",
    "plt.ylabel('Longitude (coordinate)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40e323-46f5-4fd4-b368-36eddb60a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living15\n",
    "\n",
    "print(\"mean sqft_living15 =\", df['sqft_living15'].mean().round(1), \"ft\\u00b2\")\n",
    "print(\"median sqft_living15 =\", df['sqft_living15'].median(), \"ft\\u00b2\")\n",
    "print(\"mode sqft_living15 =\", df['sqft_living15'].mode(), \"ft\\u00b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a099785-34d1-4fa5-9ac9-e0c3d600e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['sqft_living15'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Average Living Space Size in Nearest 15 Houses')\n",
    "plt.xlabel('Area (ft\\u00b2)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['sqft_living15'])\n",
    "plt.title ('Boxplot of Average Living Space Size in Nearest 15 Houses')\n",
    "plt.ylabel('Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1128bf-ee51-4c9e-89f9-f5b7041bff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_lot15\n",
    "\n",
    "print(\"mean sqft_lot15 =\", df['sqft_lot15'].mean().round(1), \"ft\\u00b2\")\n",
    "print(\"median sqft_lot15 =\", df['sqft_lot15'].median(), \"ft\\u00b2\")\n",
    "print(\"mode sqft_lot15 =\", df['sqft_lot15'].mode(), \"ft\\u00b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4aa90-99cf-4158-93e1-75c4bba52f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a histogram and boxplot to look at the spread of the data.\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(df['sqft_lot15'], bins=147, color = 'steelblue', edgecolor='none')\n",
    "plt.title ('Histogram of Average Lot Size of the Nearest 15 Houses')\n",
    "plt.xlabel('Area (ft\\u00b2)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.boxplot(df['sqft_lot15'])\n",
    "plt.title ('Boxplot of Average Lot Size of the Nearest 15 Houses')\n",
    "plt.ylabel('Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db271d1d-2296-4718-a70f-5588cd4c2c1d",
   "metadata": {},
   "source": [
    "**2.3 Diagnose for correlations between variables and determine independent and dependent variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249f3da-9254-4b5a-a587-4933a6fd81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573006e-8518-4086-8cce-bc862b5ac446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create upper triangle mask\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "\n",
    "# Plot heatmap with masked lower triangle\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    corr_matrix, \n",
    "    mask=mask,          # mask the lower triangle\n",
    "    annot=True,          # show values\n",
    "    fmt=\".2f\",           # number format\n",
    "    cmap=\"coolwarm\", \n",
    "    vmin=-1, vmax=1, \n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "plt.title(\"Lower Triangle Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb53a7-28bb-4a71-8da1-5a5139a686d0",
   "metadata": {},
   "source": [
    "I used ChatGPT to help me figure out how to print the correlation table and color the cells using a heatmap. I was able to create an incomplete correlation table, see above (because it included the 1.0 and duplicate values), but that was not conducive to reporting the values.\n",
    "Therefore, I asked ChatGPT to help me to generate a refined correlation table with a color scale to identify strong correlations.\n",
    "\n",
    "Chatgpt. (n.d.). ChatGPT. Retrieved November 24, 2025, from https://chatgpt.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fbbc4-4ffb-4a35-960d-461e1d9bc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correlation table above contains variables that exhibit weak correlations.\n",
    "# I will filter out variables with weak correlation values (< |0.5|) and the self-correlation values.\n",
    "# I will return the variables with moderate to strong correlation values (>= |0.50|).\n",
    "\n",
    "high_corr = ((corr_matrix.abs() > 0.49) & (corr_matrix.abs() < 1))\n",
    "high_corr.columns[high_corr.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771dfb3-7404-4895-abcd-d69fa573a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reduced correlation matrix will be used to visualize the moderate to strong correlations only.\n",
    "\n",
    "corr_col = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'grade', 'sqft_above', 'yr_built', 'zipcode', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "corr_matrix_red = df[corr_col].corr()\n",
    "corr_matrix_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9475c-a55c-462b-bbe4-ec8850c7ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create upper triangle mask\n",
    "mask1 = np.triu(np.ones_like(corr_matrix_red, dtype=bool), k=1)\n",
    "\n",
    "# Plot heatmap with masked lower triangle\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    corr_matrix_red, \n",
    "    mask=mask1,          # mask the lower triangle\n",
    "    annot=True,          # show values\n",
    "    fmt=\".2f\",           # number format\n",
    "    cmap=\"coolwarm\", \n",
    "    vmin=-1, vmax=1, \n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "plt.title(\"Reduced Lower Triangle Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732be211-401c-446c-b6b8-10366cf57d5c",
   "metadata": {},
   "source": [
    "Of the 13 variables with moderate to strong correlation values, **price** appears to be a dependent variable with moderately positive correlations with independent variables such as living area size (0.69), grade (0.67), area above (0.61), and the average living area of 15 nearby houses (0.59).\n",
    "\n",
    "The **living area size**, a potential dependent variable, has strong correlations with likely independent variables such as the area above (0.86), grade (0.75), average living area of 15 nearby houses (0.74), and number of bathrooms (0.72).\n",
    "\n",
    "The **area of the lot**, a dependent variable, has a strong positive correlation with the average lot areas of 15 nearby houses (0.72), a potential predictor.\n",
    "\n",
    "The **average living area of 15 nearby houses**, an unlikely dependent variable, has strong positive correlations with the grade of the house (0.71), area above (0.73), and living area (0.74).\n",
    "\n",
    "These relationships will be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f907d3-cd42-46a6-8bfd-461759118ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. sqft_living (and grade)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_living'], df['price'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_living'], df['price'], 1)\n",
    "line = slope * df['sqft_living'] + intercept\n",
    "plt.plot(df['sqft_living'], line, color = 'red')\n",
    "plt.text(500, 7500000, (\"price =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_living\"))\n",
    "\n",
    "print(\"slope =\", str(round(slope, 2)))\n",
    "print(\"intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Price and Living Area Colored by Grade')\n",
    "plt.xlabel('Living Area (ft\\u00b2)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa16d55-843a-423b-8535-393977cdeb4d",
   "metadata": {},
   "source": [
    "The Bobbit (2020) webpage was used to help me find the code to create a scatter plot with a color scheme from a third column. In this case, I plotted living area on the x-axis and price on the y-axis while color-coding the data points by grade of the house. (Grade was selected for color coding because it is a categorical dataset.) The color coding itself was very useful, however I still required a reference to the magnitudes described by the color. As such, I sought a color bar to provide a scale for the grade of each house. This is when I turned to GeeksforGeeks (2020). I used a single line of code in their example to build the color bar on the existing scatter plot. Lastly, I wanted to fit a trendline to the scatter plot data to visualize the relationship described in the correlation table. Therefore, I referenced the code written in GeeksforGeeks (2024) to create a best fit line.\n",
    "\n",
    "Bobbitt, Z. (2020, September 3). Matplotlib: How to color a scatterplot by value. Statology. https://www.statology.org/matplotlib-scatterplot-color-by-value/\n",
    "\n",
    "How to draw a line inside a scatter plot. (2024, July 22). GeeksforGeeks. https://www.geeksforgeeks.org/data-visualization/how-to-draw-a-line-inside-a-scatter-plot/\n",
    "\n",
    "Matplotlib.pyplot.colorbar() function in Python. (2020, December 5). GeeksforGeeks. https://www.geeksforgeeks.org/python/matplotlib-pyplot-colorbar-function-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f445c-e74d-449f-9569-0da0f2cdce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_scaled = df.copy()\n",
    "\n",
    "norm_col = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'grade', 'sqft_above', 'yr_built', 'zipcode', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "z_scaled[norm_col] = zscore(z_scaled[norm_col])\n",
    "print(z_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327851e5-6fb9-483c-a278-674261ffa163",
   "metadata": {},
   "source": [
    "Normalizing the data opens the door to modeling. Therefore, I referenced the GeeksforGeeks (2021) webpage to standardize the graphed data by their respective z-scores. Normalizing allows for a proper comparison between two variables on a common scale, which is the deviation from the mean, which is set at zero.\n",
    "\n",
    "How to standardize data in a pandas dataframe? (2021, December 16). GeeksforGeeks. https://www.geeksforgeeks.org/python/how-to-standardize-data-in-a-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c6678-d99b-48aa-ac46-9c63cfc7a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. sqft_living (and grade), normalized\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_living'], z_scaled['price'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_living'], z_scaled['price'], 1)\n",
    "line = slope * z_scaled['sqft_living'] + intercept\n",
    "plt.plot(z_scaled['sqft_living'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_living']], z_scaled['price'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_living']], z_scaled['price'])\n",
    "\n",
    "plt.text(-2, 19, (\"price =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_living\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Price and Living Area Colored by Grade')\n",
    "plt.xlabel('Living Area (ft\\u00b2)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9f11f-3ecc-4652-8d1f-dc26b97b99b3",
   "metadata": {},
   "source": [
    "After graphing the normalized data, I wanted to return the R-squared value of the best fit line, and verify that the best fit line matches with the actual linear regression. I referenced the Bobbit (2022) webpage to obatin that data.\n",
    "\n",
    "Bobbitt, Z. (2022, March 24). How to calculate r-squared in python(With example). Statology. https://www.statology.org/r-squared-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd164013-9196-476d-835a-b839d1eb480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. grade\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['grade'], df['price'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['grade'], df['price'], 1)\n",
    "line = slope * df['grade'] + intercept\n",
    "plt.plot(df['grade'], line, color = 'red')\n",
    "plt.text(1, 7300000, (\"price =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*grade\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Price and Grade')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f10449-f034-4342-94be-c175d42b487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. grade, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['grade'], z_scaled['price'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['grade'], z_scaled['price'], 1)\n",
    "line = slope * z_scaled['grade'] + intercept\n",
    "plt.plot(z_scaled['grade'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['grade']], z_scaled['price'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['grade']], z_scaled['price'])\n",
    "\n",
    "plt.text(-5.8, 19, (\"price =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*grade\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Price and Grade')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482ca4b-811c-4af6-9eb6-21ff5a1b5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. sqft_above (and grade)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_above'], df['price'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_above'], df['price'], 1)\n",
    "line = slope * df['sqft_above'] + intercept\n",
    "plt.plot(df['sqft_above'], line, color = 'red')\n",
    "plt.text(500, 7500000, (\"price =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_above\"))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Price and Area Above Colored by Grade')\n",
    "plt.xlabel('Area Above (ft\\u00b2)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922209d4-5035-4e92-af0f-6dd5dfdb8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. sqft_above (and grade), normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_above'], z_scaled['price'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_above'], z_scaled['price'], 1)\n",
    "line = slope * z_scaled['sqft_above'] + intercept\n",
    "plt.plot(z_scaled['sqft_above'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_above']], z_scaled['price'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_above']], z_scaled['price'])\n",
    "\n",
    "plt.text(-2, 19, (\"price =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_above\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Price and Area Above Colored by Grade')\n",
    "plt.xlabel('Area Above (ft\\u00b2)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50cc3f5-2abc-4e92-ac07-5aa7a3ee924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. sqft_living15\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_living15'], df['price'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_living15'], df['price'], 1)\n",
    "line = slope * df['sqft_living15'] + intercept\n",
    "plt.plot(df['sqft_living15'], line, color = 'red')\n",
    "plt.text(500, 7500000, (\"price =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_living15\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Price and Average Living Area of Nearby Houses Colored by Grade')\n",
    "plt.xlabel('Living Area (ft\\u00b2)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ec5de-b97c-4e0c-a9c6-6e317dcb88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs. sqft_living15, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_living15'], z_scaled['price'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_living15'], z_scaled['price'], 1)\n",
    "line = slope * z_scaled['sqft_living15'] + intercept\n",
    "plt.plot(z_scaled['sqft_living15'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_living15']], z_scaled['price'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_living15']], z_scaled['price'])\n",
    "\n",
    "plt.text(-2.3, 18.5, (\"price =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_living15\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Price and Living Area of Nearby Houses Colored by Grade')\n",
    "plt.xlabel('Living Area (ft\\u00b2)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d0845-5b43-4b78-87a0-909fccc62dd9",
   "metadata": {},
   "source": [
    "To varying yet moderate degrees, the house prices are influenced by the area above, grade, average living area of the 15 nearby houses, and number of bathrooms. These, among other factors, would predictably play a role in the overall price of a house. However, the factors not included did not exhibit, at minimum, correlation values of 0.59 or greater. All of the variables graphed on the x-axis exhibited a positive relationship with price. Ultimately, the R-squared values did not exceed 0.7, which means that no single independent variable could reliably explain the variation in house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc352ae2-fed5-43e9-90c2-2af35eb59b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# living area vs. area above\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_above'], df['sqft_living'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_above'], df['sqft_living'], 1)\n",
    "line = slope * df['sqft_above'] + intercept\n",
    "plt.plot(df['sqft_above'], line, color = 'red')\n",
    "plt.text(200, 11800, (\"sqft_living =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_above\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Living Area and Area Above Colored by Grade')\n",
    "plt.xlabel('Area Above (ft\\u00b2)')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa7606-6d18-405e-9bba-eeb7a3728bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living vs. sqft_above, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_above'], z_scaled['sqft_living'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_above'], z_scaled['sqft_living'], 1)\n",
    "line = slope * z_scaled['sqft_above'] + intercept\n",
    "plt.plot(z_scaled['sqft_above'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_above']], z_scaled['sqft_living'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_above']], z_scaled['sqft_living'])\n",
    "\n",
    "plt.text(-2, 10.5, (\"sqft_living =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_above\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Living Area and Area Above Colored by Grade')\n",
    "plt.xlabel('Area Above (ft\\u00b2)')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4543aa-8edf-4d61-a08f-dfacf23c09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living vs. grade\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['grade'], df['sqft_living'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['grade'], df['sqft_living'], 1)\n",
    "line = slope * df['grade'] + intercept\n",
    "plt.plot(df['grade'], line, color = 'red')\n",
    "plt.text(1, 11500, (\"sqft_living =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*grade\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Living Area and Grade')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdf190-594a-44b8-a4c8-b4f16923d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living vs. grade, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['grade'], z_scaled['sqft_living'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['grade'], z_scaled['sqft_living'], 1)\n",
    "line = slope * z_scaled['grade'] + intercept\n",
    "plt.plot(z_scaled['grade'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['grade']], z_scaled['sqft_living'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['grade']], z_scaled['sqft_living'])\n",
    "\n",
    "plt.text(-5.7, 10.5, (\"sqft_living =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*grade\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Living Area and Grade')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e0c0a-b9c0-4558-99f7-bcc92a38123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living vs. sqft_living15\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_living15'], df['sqft_living'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_living15'], df['sqft_living'], 1)\n",
    "line = slope * df['sqft_living15'] + intercept\n",
    "plt.plot(df['sqft_living15'], line, color = 'red')\n",
    "plt.text(200, 11200, (\"sqft_living =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_living15\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Living Area and Living Area of Nearby Houses Colored by Grade')\n",
    "plt.xlabel('Living Area of Nearby Houses (ft\\u00b2)')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e7d56-558b-4385-b78a-b5d67c585b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living vs. sqft_living15, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_living15'], z_scaled['sqft_living'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_living15'], z_scaled['sqft_living'], 1)\n",
    "line = slope * z_scaled['sqft_living15'] + intercept\n",
    "plt.plot(z_scaled['sqft_living15'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_living15']], z_scaled['sqft_living'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_living15']], z_scaled['sqft_living'])\n",
    "\n",
    "plt.text(-2, 10.1, (\"sqft_living =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_living15\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Living Area and Living Area of Nearby Houses Colored by Grade')\n",
    "plt.xlabel('Living Area of Nearby Houses (ft\\u00b2)')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85481e-2e3c-493a-939a-ee6f2af317d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living vs. bathrooms\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['bathrooms'], df['sqft_living'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['bathrooms'], df['sqft_living'], 1)\n",
    "line = slope * df['bathrooms'] + intercept\n",
    "plt.plot(df['bathrooms'], line, color = 'red')\n",
    "plt.text(0, 11800, (\"sqft_living =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*bathrooms\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Living Area and Number of Bathrooms Colored by Grade')\n",
    "plt.xlabel('Number of Bathrooms')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c63a6-3b68-4c9d-8ba0-b5255ea6822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living vs. bathrooms, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['bathrooms'], z_scaled['sqft_living'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['bathrooms'], z_scaled['sqft_living'], 1)\n",
    "line = slope * z_scaled['bathrooms'] + intercept\n",
    "plt.plot(z_scaled['bathrooms'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['bathrooms']], z_scaled['sqft_living'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['bathrooms']], z_scaled['sqft_living'])\n",
    "\n",
    "plt.text(-3, 10.7, (\"sqft_living =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*bathrooms\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Living Area and Area Above Colored by Grade')\n",
    "plt.xlabel('Number of Bathrooms')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc081e8-2178-4ea2-bd9e-2b515bd0e2b8",
   "metadata": {},
   "source": [
    "To varying yet strong degrees, the living area is influenced by the area above, grade, average living area of 15 nearby houses, and the number of bathrooms. These, among other factors, would predictably play a role in the overall living area of a house. However, the factors not included did not exhibit, at minimum, correlation values of 0.7 or greater. Understandably, all of the variables graphed on the x-axis exhibited a positive relationship with living area. Ultimately, the R-squared values did not exceed 0.7, which means that no single independent variable could reliably explain the variation in living area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285143c2-05c3-4cd9-80b9-67fefe264436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_lot vs. sqft_lot15\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_lot15'], df['sqft_lot'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_lot15'], df['sqft_lot'], 1)\n",
    "line = slope * df['sqft_lot15'] + intercept\n",
    "plt.plot(df['sqft_lot15'], line, color = 'red')\n",
    "plt.text(0, 1500000, (\"sqft_lot =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_lot15\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Lot Area and Lot Area of Nearby Houses')\n",
    "plt.xlabel('Lot Area of Nearby Houses (ft\\u00b2)')\n",
    "plt.ylabel('Lot Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768f0f7-a9cf-4fea-9786-3643ad5f207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_lot vs. sqft_lot15, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_lot15'], z_scaled['sqft_lot'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_lot15'], z_scaled['sqft_lot'], 1)\n",
    "line = slope * z_scaled['sqft_lot15'] + intercept\n",
    "plt.plot(z_scaled['sqft_lot15'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_lot15']], z_scaled['sqft_lot'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_lot15']], z_scaled['sqft_lot'])\n",
    "\n",
    "plt.text(0, 35, (\"sqft_lot =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_lot15\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Lot Area and Lot Area of Nearby Houses')\n",
    "plt.xlabel('Lot Area of Nearby Houses (ft\\u00b2)')\n",
    "plt.ylabel('Lot Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da12f5-b504-4ba2-8e58-8f201edc6c63",
   "metadata": {},
   "source": [
    "The slope of the scatter plots help to confirm the strong positive correlation value between lot area and the lot areas of 15 nearby houses. Ultimately, the R-squared value did not exceed 0.7, which means that lot area of 15 nearby houses alone cannot reliably explain the variation in lot area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51c502-f8c4-4ad9-a194-91555f93ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living15 vs. grade\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['grade'], df['sqft_living15'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['grade'], df['sqft_living15'], 1)\n",
    "line = slope * df['grade'] + intercept\n",
    "plt.plot(df['grade'], line, color = 'red')\n",
    "plt.text(1, 6000, (\"sqft_living15 =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*grade\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Living Area of 15 Nearby Houses and Grade')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a5b55-264b-48cb-a389-90545cc6eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living15 vs. grade, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['grade'], z_scaled['sqft_living15'], s = 10)\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['grade'], z_scaled['sqft_living15'], 1)\n",
    "line = slope * z_scaled['grade'] + intercept\n",
    "plt.plot(z_scaled['grade'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['grade']], z_scaled['sqft_living15'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['grade']], z_scaled['sqft_living15'])\n",
    "\n",
    "plt.text(-5.7, 5.8, (\"sqft_living15 =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*grade\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Living Area of Nearby Houses and Grade')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877495f-c7d7-4a35-8071-fde5d9804086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# living area vs. area above\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_above'], df['sqft_living15'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_above'], df['sqft_living15'], 1)\n",
    "line = slope * df['sqft_above'] + intercept\n",
    "plt.plot(df['sqft_above'], line, color = 'red')\n",
    "plt.text(100, 6500, (\"sqft_living15 =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_above\"))\n",
    "\n",
    "print(\"best fit slope =\", round(slope, 2))\n",
    "print(\"best fit intercept =\", round(intercept, 2))\n",
    "\n",
    "plt.title ('Scatter Plot of Living Area of Nearby Houses and Area Above Colored by Grade')\n",
    "plt.xlabel('Area Above (ft\\u00b2)')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9c153-d6fa-44c7-9a05-ffda052d20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living15 vs. sqft_above, normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_above'], z_scaled['sqft_living15'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_above'], z_scaled['sqft_living15'], 1)\n",
    "line = slope * z_scaled['sqft_above'] + intercept\n",
    "plt.plot(z_scaled['sqft_above'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_above']], z_scaled['sqft_living15'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_above']], z_scaled['sqft_living15'])\n",
    "\n",
    "plt.text(-2, 6.5, (\"sqft_living15 =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_above\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Living Area of Nearby Houses and Area Above Colored by Grade')\n",
    "plt.xlabel('Area Above (ft\\u00b2)')\n",
    "plt.ylabel('Living Area (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd8914-7f60-4723-8102-b3bd8389d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living15 vs. sqft_living (and grade)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(df['sqft_living'], df['sqft_living15'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(df['sqft_living'], df['sqft_living15'], 1)\n",
    "line = slope * df['sqft_living'] + intercept\n",
    "plt.plot(df['sqft_living'], line, color = 'red')\n",
    "plt.text(200, 7400, (\"sqft_living15 =\" + str(round(intercept, 2)) + \"+\" + str(round(slope, 2)) + \"*sqft_living\"))\n",
    "\n",
    "print(\"slope =\", str(round(slope, 2)))\n",
    "print(\"intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Living Area of Nearby Houses and Living Area Colored by Grade')\n",
    "plt.xlabel('Living Area (ft\\u00b2)')\n",
    "plt.ylabel('Living Area of Nearby Houses (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040a707-d662-4d7f-a917-367e8fcacfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft_living15 vs. sqft_living (and grade), normalized\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(z_scaled['sqft_living'], z_scaled['sqft_living15'], s = 10, c = df['grade'], cmap = 'viridis')\n",
    "plt.colorbar(label = \"Grade\", orientation = \"vertical\")\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(z_scaled['sqft_living'], z_scaled['sqft_living15'], 1)\n",
    "line = slope * z_scaled['sqft_living'] + intercept\n",
    "plt.plot(z_scaled['sqft_living'], line, color = 'red')\n",
    "\n",
    "# creating a linear regression model from the normalized data\n",
    "model = LinearRegression()\n",
    "model.fit(z_scaled[['sqft_living']], z_scaled['sqft_living15'])\n",
    "slope_m = model.coef_[0]\n",
    "intercept_m = model.intercept_\n",
    "r_squared = model.score(z_scaled[['sqft_living']], z_scaled['sqft_living15'])\n",
    "\n",
    "plt.text(-2, 7.8, (\"sqft_living15 =\" + str(round(intercept_m, 2)) + \"+\" + str(round(slope_m, 2)) + \"*sqft_living\" + ', R\\u00b2 =' + str(round(r_squared, 2))))\n",
    "\n",
    "print(\"best fit slope =\", str(round(slope, 2)))\n",
    "print(\"best fit intercept =\", str(round(intercept, 2)))\n",
    "\n",
    "print(\"model slope =\", round(slope_m, 2))\n",
    "print(\"model intercept =\", round(intercept_m, 2))\n",
    "print ('model R\\u00b2 =', str(round(r_squared, 2)))\n",
    "\n",
    "plt.title ('Scatter Plot of Normalized Living Area of Nearby Houses and Living Area Colored by Grade')\n",
    "plt.xlabel('Living Area (ft\\u00b2)')\n",
    "plt.ylabel('Living Area of Nearby Houses (ft\\u00b2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279eda70-7d1f-4a3b-b3e0-e94174b46d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot\n",
    "sc = plt.scatter(\n",
    "    df['long'],       # x-axis = longitude\n",
    "    df['lat'],        # y-axis = latitude\n",
    "    c=df['price'],    # color by 'price'\n",
    "    cmap='viridis',         # colormap\n",
    "    s=20,                   # marker size\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.colorbar(sc, label='Price ($)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Houses Colored by Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45aa37-7602-4550-9226-fea3171255e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot\n",
    "sc = plt.scatter(\n",
    "    df['long'],       # x-axis = longitude\n",
    "    df['lat'],        # y-axis = latitude\n",
    "    c=df['zipcode'],    # color by 'price'\n",
    "    cmap='viridis',         # colormap\n",
    "    s=20,                   # marker size\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.colorbar(sc, label='Zipcode')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Houses Colored by Zipcode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0a023-d1fd-4114-923b-bf5e8f02b1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c34cb-ef9c-4340-9f8f-b83ab7c3395a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31438888-418a-412e-890f-1fc0ccb456fc",
   "metadata": {},
   "source": [
    "# **STEP 3: Data Analytics**\n",
    "## -Determine the need for a supervised or unsupervised learning method and identify dependent and independent variables\n",
    "## -Train, test, and provide accuracy and evaluation metrics for model results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbd563-9800-47ca-9aff-5132dc5c6354",
   "metadata": {},
   "source": [
    "For this portion, we will focus on supervised machine learning because we have already identified labels for our independent variables. This method will ensure that our model accurately predicts results for our testing data, increasing generalizability for populations outside of our sample. \n",
    "The dependent variable will be price, and independent variables will be the features that had a correlation of above the absolute value of 0.5. These include: the size of nearby houses, squarefoot living, squarefoot above, number of bathrooms, and grade. We will perform regression to deal with continuous data points, where classification would be inappropriate. We will first use linear regression to determine accuracy, then move on to random forrest regression to better fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6d4fb-fb19-4ebf-8faf-a68a1b75030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold #used to split the data into training and testing groups\n",
    "from sklearn.linear_model import LinearRegression #we will perform linear regression using this function\n",
    "from sklearn.metrics import mean_absolute_error #used for evaluating the accuracy of our ML model\n",
    "from sklearn.ensemble import RandomForestRegressor #we will use this for a more reliable model build for non-linear relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7f431178-bec1-4643-a324-3c179596cf21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[288], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#for interactions between variables, random forest is more appropriate because we can "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b505fc-1236-43c8-b678-0fd58c6cd80e",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc858c-6817-4c6c-8303-7087395e28ff",
   "metadata": {},
   "source": [
    "Bobbitt, Z. (2020, September 3). Matplotlib: How to color a scatterplot by value. Statology. https://www.statology.org/matplotlib-scatterplot-color-by-value/\n",
    "\n",
    "Bobbitt, Z. (2022, March 24). How to calculate r-squared in python(With example). Statology. https://www.statology.org/r-squared-in-python/\n",
    "\n",
    "How to draw a line inside a scatter plot. (2024, July 22). GeeksforGeeks. https://www.geeksforgeeks.org/data-visualization/how-to-draw-a-line-inside-a-scatter-plot/\n",
    "\n",
    "How to standardize data in a pandas dataframe? (2021, December 16). GeeksforGeeks. https://www.geeksforgeeks.org/python/how-to-standardize-data-in-a-pandas-dataframe/\n",
    "\n",
    "Matplotlib.pyplot.colorbar() function in Python. (2020, December 5). GeeksforGeeks. https://www.geeksforgeeks.org/python/matplotlib-pyplot-colorbar-function-in-python/\n",
    "\n",
    "https://medium.com/@sarah.ahmed.aboelseoud/beyond-the-numbers-understanding-linear-regression-modeling-2c9ae5697199 \n",
    "\n",
    "Pandas. Dataframe. Select_dtypes—Pandas 2. 3. 3 documentation. (n.d.). Retrieved November 24, 2025, from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html\n",
    "\n",
    "Shah, C. (2020). A Hands-On Introduction to Data Science. Cambridge: Cambridge University Press. Accessed via web: https://www.cambridge.org/highereducation/books/a-hands-on-introduction-to-data-science/9D55C29C653872F13289EA7909953842#overview \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0a167-10bd-40bf-a797-73085be489bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
